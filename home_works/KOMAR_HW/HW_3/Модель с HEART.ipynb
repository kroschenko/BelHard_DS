{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3790574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #импортировали функцию для разделения датасета на обучающую и тестовую выборки\n",
    "\n",
    "data = pd.read_csv(\"heart.csv\")\n",
    "x = data.drop(\"target\", axis=1) #это признаки + удаляем целевой столбец, axis=1 - операция выполняется по столбцу\n",
    "y = data[\"target\"] #это целевой столбец\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)  #делим на обучающую и тестовую выборку, 0.2 - размер тестовой выборки, 42 - рандом для выбора, stratify=y - чтоб целевая переменная распределилась равномерно в обучающей и тестовой выборке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB #наивный байес\n",
    "from sklearn.linear_model import LogisticRegression #лог регрессия\n",
    "from sklearn.neighbors import KNeighborsClassifier #метод k-ближайших соседей\n",
    "\n",
    "nb_model = GaussianNB() #создвм модель наивный байес \n",
    "nb_model.fit(x_train, y_train) #ообучаем\n",
    "\n",
    "log_model = LogisticRegression(max_iter=5000) #создвм модель лог регрессии, 1000 - кол-во иитераций, \n",
    "log_model.fit(x_train, y_train) #обучаем\n",
    "\n",
    "best_k = None #пока мы не знаем, какое k лучше всего подходит для модели, поэтому ставим None\n",
    "best_score = 0 #начальное значение точности\n",
    "for k in range(1, 21):  # цикл для проверки k от 1 до 20\n",
    "    knn = KNeighborsClassifier(n_neighbors=k) #создаем модель\n",
    "    knn.fit(x_train, y_train) #обучаем модель\n",
    "    score = knn.score(x_test, y_test)  # \"Метод .score() для классификаторов в sklearn возвращает accuracy (долю правильных предсказаний)\"\n",
    "    if score > best_score: #если текущая модель точнее предыдущих, то сохраняются показатели при этой модели\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k) #создаем модель с наилучшик k полученным выше\n",
    "knn_model.fit(x_train, y_train) #обчаем модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score #импортируем 1) матрицу ошибок, 2) точность для правильных предсказаний, 3) точность насколько предсказания класса 1 действительно верны, 4) насколько модель нашла все объекты класса 1, \"гармоническое среднее между precision и recall (баланс между ними)\"\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": nb_model,\n",
    "    \"Logistic Regression\": log_model,\n",
    "    \"KNN\": knn_model\n",
    "} #словарь моделей\n",
    "\n",
    "for name, model in models.items(): # перебираем каждую пару - название модели и объект модели\n",
    "    y_pred = model.predict(x_test) #предсказания модели на тестовой выборке\n",
    "    print(f\"\\n{name}\") \n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred)) # \"Показываем, сколько объектов модель классифицировала правильно и где ошиблась:\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred)) #доля правильных предсказаний\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred)) #bз всех предсказаний класса 1 сколько действительно были класса 1 \"Формула: TP / (TP + FP)\"\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred)) #из всех настоящих объектов класса 1 сколько модель нашла \"Формула: TP / (TP + FN)\"\n",
    "    print(\"F1-score:\", f1_score(y_test, y_pred)) #баланс между precision и recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ddc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc #roc_curve - функция для построения рок кривой, \"auc — вычисляет площадь под ROC-кривой (AUC), которая показывает качество модели: чем ближе к 1, тем лучше.\"\n",
    "\n",
    "for name, model in models.items(): \n",
    "    y_prob = model.predict_proba(x_test)[:,1] #вероятности принадлежности к каждому классу, берём вероятность принадлежности к классу 1\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob) # Строим рок кривую\n",
    "    roc_auc = auc(fpr, tpr) #\"auc() считает площадь под кривой — чем больше, тем лучше модель различает классы\"\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\") #рисуем кривые и легенду\n",
    "\n",
    "plt.plot([0,1], [0,1])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-кривые для моделей\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
